Steven Choi
Professor Liang
C.S. 540
4 February 2019
�Self Driving Cars�
	Currently, there are many companies that are trying to master the concept of a self driving vehicle. Although making the vehicle drive a set distance from a car on the road, never making it drive faster than the speed limit, and having it respond to traffic lights are an easy concept and would be simple enough to code with today�s technology. However, having a moral aspect in a self driving vehicle is the troublesome task that may not be able to make self driving vehicles perfect in the next few years. For example, when given a normal driver, one without a self driving vehicle, suddenly slams on the break because a drunk person jumped out on the street, would the self driving car kill the car in front, or turn to potentially harm the driver and citizens? If someone got hurt, will we blame the driver or the company for legal charges? What if it was snowing and raining and the camera don�t have any vision and the roads are more slippery? There are too many environmental and moral aspects to take into account that we can�t simply manage to compile with today�s technology. It would require billions and billions of decisions, every single possible event has to be calculated and the space that data will take up will be unfathomable. Uber and Tesla went on and released self driving vehicles to the public before they could figure out the moral aspect of A.I. therefore, people were killed in the accident that a self driving vehicle made. In order to perfect self driving vehicles, the vehicle would have to be able to think like a human and we would need a social structure capable of taking account the legal aspects and �the one to blame� if a fatal accident should occur. Because of this, I believe that A.I cannot perfect self driving vehicles in the next century.
	
